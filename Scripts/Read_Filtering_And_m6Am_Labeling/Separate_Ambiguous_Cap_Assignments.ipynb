{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41adfe62-1910-4b89-8d06-3319b52f9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "cap1Am = np.load(\"cap1_Am_nm.npy\", allow_pickle = True)\n",
    "cap1m6Am = np.load(\"cap1_m6Am_nm.npy\", allow_pickle = True)\n",
    "\n",
    "cap2Am = np.load(\"cap2_Am_nm.npy\", allow_pickle = True)\n",
    "cap2m6Am = np.load(\"cap2_m6Am_nm.npy\", allow_pickle = True)\n",
    "\n",
    "pos_count2Am_filt = []\n",
    "pos_count2m6Am_filt = []\n",
    "\n",
    "pos_count1Am_filt = []\n",
    "pos_count1m6Am_filt = []\n",
    "\n",
    "cap1 = np.concatenate((cap1Am, cap1m6Am))\n",
    "cap2 = np.concatenate((cap2Am, cap2m6Am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362509c5-e50c-46ff-b318-bdaf262e7647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of position information and sequence information for cap1 reads\n",
    "pos_count2_dups = []\n",
    "pos_count1_dict = {}\n",
    "for pos in cap1:\n",
    "    key = ((pos[4])[:40])\n",
    "    pos_count1_dict[key] = pos[0:5]\n",
    "\n",
    "# If a cap2 read matches position and sequence information, it is appended to pos_count2_dups as it is an ambiguous cap1/cap2 read\n",
    "for seq in tqdm(cap2):\n",
    "    key = ((seq[4])[:40])\n",
    "    if key in pos_count1_dict:\n",
    "        pos_count2_dups.append(seq[0:5])\n",
    "\n",
    "# A dictionary is made of the position for all ambiguous cap1/cap2 reads found above\n",
    "pos_count2_dups_more = np.array(pos_count2_dups)     \n",
    "pos_count1_dups_dict = {}\n",
    "for pos in pos_count2_dups_more:\n",
    "    key = tuple(pos[0:4])\n",
    "    pos_count1_dups_dict[key] = pos[0:5]\n",
    "\n",
    "# If a read has the same position information as the ambiguous read added to pos_count2_dups, then it is also added to pos_count2_dups so it can be later removed\n",
    "for seq in tqdm(cap2):\n",
    "    key = tuple(seq[0:4])\n",
    "    if key in pos_count1_dups_dict:\n",
    "        pos_count2_dups.append(seq[0:5])\n",
    "\n",
    "# A dictionary is made of all reads that should be discarded since they are ambiguous or correspond to the site of an ambiuous read\n",
    "pos_count2_dups = np.array(pos_count2_dups)\n",
    "ambAm = []\n",
    "ambm6Am = []\n",
    "pos_count2_dups_remove = {}\n",
    "for pos in pos_count2_dups:\n",
    "    key = tuple(pos[0:5])\n",
    "    pos_count2_dups_remove[key] = pos[0:5]\n",
    "\n",
    "# Those reads that are not in the dictionary of reads to remove are saved as a filtered array of cap2 reads\n",
    "for seq in tqdm(cap2Am):\n",
    "    key = tuple(seq[0:5])\n",
    "    if key not in pos_count2_dups_remove:\n",
    "        pos_count2Am_filt.append(seq)\n",
    "    if key in pos_count2_dups_remove:\n",
    "        ambAm.append(seq)\n",
    "\n",
    "for seq in tqdm(cap2m6Am):\n",
    "    key = tuple(seq[0:5])\n",
    "    if key not in pos_count2_dups_remove:\n",
    "        pos_count2m6Am_filt.append(seq)\n",
    "    if key in pos_count2_dups_remove:\n",
    "        ambm6Am.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f47eab2-6560-416f-b9f5-64604dae4987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 63698/63698 [00:00<00:00, 1885506.83it/s]\n",
      "100%|████████████████████████████████| 63698/63698 [00:00<00:00, 1391765.00it/s]\n",
      "100%|████████████████████████████████| 46557/46557 [00:00<00:00, 1842452.88it/s]\n",
      "100%|████████████████████████████████| 17141/17141 [00:00<00:00, 1850282.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# The same process is repeated for filtering cap1 reads\n",
    "\n",
    "pos_count1_dups = []\n",
    "\n",
    "pos_count2_dict = {} \n",
    "\n",
    "for pos in cap2:\n",
    "    key = ((pos[4])[:40])\n",
    "    pos_count2_dict[key] = pos[0:5]\n",
    "\n",
    "for seq in tqdm(cap1): \n",
    "    key = ((seq[4])[:40])\n",
    "    if key in pos_count2_dict:\n",
    "        pos_count1_dups.append(seq[0:5])\n",
    "\n",
    "pos_count1_dups_more = np.array(pos_count1_dups)     \n",
    "\n",
    "pos_count2_dups_dict = {}\n",
    "\n",
    "for pos in pos_count1_dups_more:\n",
    "    key = tuple(pos[0:4]) \n",
    "    pos_count2_dups_dict[key] = pos[0:5]\n",
    "\n",
    "for seq in tqdm(cap1):\n",
    "    key = tuple(seq[0:4])\n",
    "    if key in pos_count2_dups_dict:\n",
    "        pos_count1_dups.append(seq[0:5]) \n",
    "\n",
    "pos_count1_dups = np.array(pos_count1_dups)\n",
    "\n",
    "pos_count1_dups_remove = {}\n",
    "for pos in pos_count1_dups:\n",
    "    key = tuple(pos[0:5])\n",
    "    pos_count1_dups_remove[key] = pos[0:5]\n",
    "\n",
    "for seq in tqdm(cap1Am):\n",
    "    key = tuple(seq[0:5])\n",
    "    if key not in pos_count1_dups_remove: \n",
    "        pos_count1Am_filt.append(seq)\n",
    "\n",
    "for seq in tqdm(cap1m6Am):\n",
    "    key = tuple(seq[0:5])\n",
    "    if key not in pos_count1_dups_remove: \n",
    "        pos_count1m6Am_filt.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621d8479-037e-4c2d-a02e-64889891e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count2Am_filt = np.array(pos_count2Am_filt)\n",
    "pos_count1Am_filt = np.array(pos_count1Am_filt)\n",
    "pos_count2m6Am_filt = np.array(pos_count2m6Am_filt)\n",
    "pos_count1m6Am_filt = np.array(pos_count1m6Am_filt)\n",
    "ambAm = np.array(ambAm)\n",
    "ambm6Am = np.array(ambm6Am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3b4721-7784-4ae1-af15-74c7dd2096d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not removing ambgiuous reads, save cap1 and cap2 arrays instead\n",
    "np.save(\"filtered_cap1_Am.npy\", pos_count1Am_filt)\n",
    "np.save(\"filtered_cap2_Am.npy\", pos_count2Am_filt)\n",
    "np.save(\"filtered_cap1_m6Am.npy\", pos_count1m6Am_filt)\n",
    "np.save(\"filtered_cap2_m6Am.npy\", pos_count2m6Am_filt)\n",
    "np.save(\"ambiguous_reads_Am.npy\", ambAm)\n",
    "np.save(\"ambiguous_reads_m6Am.npy\", ambm6Am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7eda4-d7b5-4e21-b743-d8f183584778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
